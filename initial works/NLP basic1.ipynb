{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1HcHtxxNdbr",
        "outputId": "0515f3b8-93b6-4fca-9611-04c83331c298"
      },
      "source": [
        "%tensorflow_version 2.x\r\n",
        "import tensorflow as tf\r\n",
        "device_name = tf.test.gpu_device_name()\r\n",
        "if device_name != '/device:GPU:0':\r\n",
        "  raise SystemError('GPU device not found')\r\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWd2Xh_WLpxK",
        "outputId": "5699194e-d3b4-40be-f990-01df1ef35a5d"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZO2F8IvKo_j"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import re\r\n",
        "import spacy \r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem.porter import PorterStemmer\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\r\n",
        "\r\n",
        "from tensorflow.keras.preprocessing.text import one_hot\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Embedding\r\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Activation\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgEEZqk7LA-B"
      },
      "source": [
        "train = pd.read_csv('/content/train.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81Wavg8YLKLJ"
      },
      "source": [
        "train['keyword'].fillna('', inplace=True)\r\n",
        "train['text'] = train['text'] + ' ' + train['keyword']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyTDrGc3LQbA"
      },
      "source": [
        "def preprocess(text):\r\n",
        "    text = re.sub('[^a-zA-Z]', ' ', text)\r\n",
        "    text = text.lower().split()\r\n",
        "    \r\n",
        "    text = [PorterStemmer().stem(word) for word in text if not word in stopwords.words('english')]\r\n",
        "    text = ' '.join(text)\r\n",
        "    return text"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08ny6SvlLZVM"
      },
      "source": [
        "train['text'] = train['text'].apply(lambda x: preprocess(x))\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9quMnbnlNoxB"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77wbF_roLjRq"
      },
      "source": [
        "voc_size = 50000\r\n",
        "sent_length = 40\r\n",
        "embedding_dim = 300\r\n",
        "\r\n",
        "X_train = [one_hot(words, voc_size) for words in train['text']]\r\n",
        "X_train = pad_sequences(X_train, padding='pre', maxlen=sent_length)\r\n",
        "Y_train = train['target']"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX3U17CJOXgz",
        "outputId": "20391115-fa22-432d-dee5-a3fbfecbf638"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Embedding(voc_size, embedding_dim, input_length=sent_length))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "\r\n",
        "model.add(LSTM(64, return_sequences=True))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "\r\n",
        "model.add(LSTM(64))\r\n",
        "model.add(Dropout(0.1))\r\n",
        "\r\n",
        "model.add(Dense(64,activation='relu'))\r\n",
        "model.add(Dense(64,activation='relu'))\r\n",
        "model.add(Activation('softmax'))\r\n",
        "model.add(Dense(1,activation='sigmoid'))\r\n",
        "\r\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\r\n",
        "model_history = model.fit(X_train, Y_train, validation_split=0.2, batch_size=64, epochs=20, shuffle=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "96/96 [==============================] - 50s 188ms/step - loss: 0.6811 - accuracy: 0.5662 - val_loss: 0.6166 - val_accuracy: 0.7814\n",
            "Epoch 2/20\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.5733 - accuracy: 0.8416 - val_loss: 0.5878 - val_accuracy: 0.7630\n",
            "Epoch 3/20\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 0.5200 - accuracy: 0.8804 - val_loss: 0.5635 - val_accuracy: 0.7833\n",
            "Epoch 4/20\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 0.4792 - accuracy: 0.9038 - val_loss: 0.5588 - val_accuracy: 0.7768\n",
            "Epoch 5/20\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 0.4412 - accuracy: 0.9200 - val_loss: 0.5414 - val_accuracy: 0.7800\n",
            "Epoch 6/20\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 0.4117 - accuracy: 0.9289 - val_loss: 0.5524 - val_accuracy: 0.7518\n",
            "Epoch 7/20\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.3848 - accuracy: 0.9371 - val_loss: 0.5478 - val_accuracy: 0.7557\n",
            "Epoch 8/20\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 0.3597 - accuracy: 0.9428 - val_loss: 0.5466 - val_accuracy: 0.7584\n",
            "Epoch 9/20\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 0.3421 - accuracy: 0.9451 - val_loss: 0.5557 - val_accuracy: 0.7459\n",
            "Epoch 10/20\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 0.3158 - accuracy: 0.9539 - val_loss: 0.5942 - val_accuracy: 0.7065\n",
            "Epoch 11/20\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 0.3030 - accuracy: 0.9522 - val_loss: 0.5613 - val_accuracy: 0.7374\n",
            "Epoch 12/20\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 0.2828 - accuracy: 0.9591 - val_loss: 0.5706 - val_accuracy: 0.7347\n",
            "Epoch 13/20\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 0.2754 - accuracy: 0.9562 - val_loss: 0.5776 - val_accuracy: 0.7420\n",
            "Epoch 14/20\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 0.2554 - accuracy: 0.9629 - val_loss: 0.6008 - val_accuracy: 0.7255\n",
            "Epoch 15/20\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 0.2432 - accuracy: 0.9644 - val_loss: 0.6124 - val_accuracy: 0.7269\n",
            "Epoch 16/20\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 0.2367 - accuracy: 0.9627 - val_loss: 0.5853 - val_accuracy: 0.7393\n",
            "Epoch 17/20\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 0.2319 - accuracy: 0.9610 - val_loss: 0.5925 - val_accuracy: 0.7439\n",
            "Epoch 18/20\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.2183 - accuracy: 0.9652 - val_loss: 0.6294 - val_accuracy: 0.7216\n",
            "Epoch 19/20\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 0.2137 - accuracy: 0.9643 - val_loss: 0.6402 - val_accuracy: 0.7163\n",
            "Epoch 20/20\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 0.2065 - accuracy: 0.9657 - val_loss: 0.6068 - val_accuracy: 0.7439\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzPxJEg2RNSo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}